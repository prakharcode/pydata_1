{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1177 at run 100\n",
      "loss 361 at run 200\n",
      "loss 241 at run 300\n",
      "loss 217 at run 400\n",
      "loss 211 at run 500\n",
      "loss 210 at run 600\n",
      "loss 209 at run 700\n",
      "loss 208 at run 800\n",
      "loss 207 at run 900\n",
      "loss 207 at run 1000\n",
      "  5.947095 seconds (811.97 k allocations: 228.417 MiB, 0.60% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "\n",
    "n_in, n_h, n_out = 5, 4, 2\n",
    "\n",
    "W1 = rand(n_h, n_in)\n",
    "W2 = rand(n_out, n_h)\n",
    "\n",
    "M = 1000 # no of training examples\n",
    "\n",
    "x_in = rand(n_in, M) \n",
    "y = rand(n_out, M)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(1,1000)\n",
    "    # forward pass\n",
    "    h = W1 * x_in\n",
    "    relu_h = max.(h, 0)\n",
    "    out = W2 * relu_h\n",
    "    \n",
    "    # calculate loss\n",
    "    \n",
    "    loss = sum((out .- y).^2)\n",
    "    \n",
    "    # backprop\n",
    "    out_grad = 2*(out - y)\n",
    "    W2_grad = out_grad * (relu_h')\n",
    "    grad_relu_h = W2' * (out_grad)\n",
    "    grad_h = copy(grad_relu_h)\n",
    "    grad_h[h .< 0] = 0\n",
    "    W1_grad = grad_h*(x_in') \n",
    "    \n",
    "    # update params\n",
    "    W1 -= learning_rate * W1_grad\n",
    "    W2 -= learning_rate * W2_grad\n",
    "    \n",
    "    if t%100==0\n",
    "        println(\"loss $(trunc(Int,loss)) at run $t\")\n",
    "    end\n",
    "end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
